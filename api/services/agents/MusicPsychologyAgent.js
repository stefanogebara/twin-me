/**
 * MusicPsychologyAgent - Specialized agent for Spotify-based personality inference
 *
 * Uses validated music psychology research to infer Big Five personality traits
 * from Spotify listening data.
 *
 * Research Foundation:
 * - Anderson et al. (2021): Spotify-personality correlations (n=5,808)
 * - Rentfrow & Gosling (2003): Music preference structure
 * - Greenberg et al. (2016): Audio feature-personality correlations
 */

import AgentBase from './AgentBase.js';
import researchRAGService from '../researchRAGService.js';
import { createClient } from '@supabase/supabase-js';

// Lazy Supabase initialization
let supabase = null;
function getSupabaseClient() {
  if (!supabase) {
    supabase = createClient(
      process.env.SUPABASE_URL,
      process.env.SUPABASE_SERVICE_ROLE_KEY
    );
  }
  return supabase;
}

// Research-validated correlations from peer-reviewed studies
const MUSIC_PERSONALITY_CORRELATIONS = {
  // Audio Features (Anderson et al. 2021, Greenberg et al. 2016)
  energy: {
    extraversion: { r: 0.35, direction: 'positive' },
    neuroticism: { r: -0.15, direction: 'negative' }
  },
  valence: {
    extraversion: { r: 0.25, direction: 'positive' },
    neuroticism: { r: -0.30, direction: 'negative' },
    agreeableness: { r: 0.15, direction: 'positive' }
  },
  tempo: {
    extraversion: { r: 0.25, direction: 'positive' }
  },
  acousticness: {
    agreeableness: { r: 0.15, direction: 'positive' },
    openness: { r: 0.20, direction: 'positive' }
  },
  danceability: {
    extraversion: { r: 0.28, direction: 'positive' }
  },

  // Behavioral Patterns
  genre_diversity: {
    openness: { r: 0.40, direction: 'positive' },
    extraversion: { r: 0.15, direction: 'positive' }
  },
  discovery_rate: {
    openness: { r: 0.35, direction: 'positive' }
  },
  listening_consistency: {
    conscientiousness: { r: 0.25, direction: 'positive' }
  },

  // Genre-Specific (Rentfrow & Gosling 2003)
  genre_reflective_complex: { // blues, jazz, classical, folk
    openness: { r: 0.40, direction: 'positive' }
  },
  genre_intense_rebellious: { // rock, metal, alternative
    openness: { r: 0.35, direction: 'positive' }
  },
  genre_upbeat_conventional: { // pop, country, religious
    conscientiousness: { r: 0.20, direction: 'positive' },
    agreeableness: { r: 0.20, direction: 'positive' },
    openness: { r: -0.25, direction: 'negative' }
  },
  genre_energetic_rhythmic: { // hip-hop, dance, electronic
    extraversion: { r: 0.30, direction: 'positive' }
  }
};

// Genre categorization mapping
const GENRE_CATEGORIES = {
  reflective_complex: ['jazz', 'blues', 'classical', 'folk', 'opera', 'world', 'new age', 'ambient'],
  intense_rebellious: ['rock', 'metal', 'alternative', 'punk', 'grunge', 'hardcore', 'indie rock'],
  upbeat_conventional: ['pop', 'country', 'religious', 'christian', 'gospel', 'adult contemporary'],
  energetic_rhythmic: ['hip-hop', 'rap', 'dance', 'electronic', 'edm', 'house', 'techno', 'disco', 'funk', 'r&b']
};

class MusicPsychologyAgent extends AgentBase {
  constructor() {
    super({
      name: 'MusicPsychologyAgent',
      role: 'Music psychology specialist for Big Five personality inference from Spotify data',
      model: 'claude-sonnet-4-20250514',
      maxTokens: 4096,
      temperature: 0.3 // Lower temperature for research-based analysis
    });

    this.correlations = MUSIC_PERSONALITY_CORRELATIONS;
    this.genreCategories = GENRE_CATEGORIES;
    this.initializeTools();
  }

  buildSystemPrompt() {
    return `You are the MusicPsychologyAgent, a specialized AI that analyzes Spotify listening data to infer Big Five personality traits using peer-reviewed music psychology research.

YOUR EXPERTISE:
You have deep knowledge of music psychology research, particularly:
- Anderson et al. (2021): "Just the Way You Are" - Spotify listening and personality (n=5,808)
- Rentfrow & Gosling (2003): Music preference structure and personality
- Greenberg et al. (2016): Audio feature correlations with personality

YOUR TASK:
1. Analyze user's Spotify data (audio features, genres, listening patterns)
2. Apply validated research correlations to infer personality traits
3. Generate evidence items with specific citations
4. Calculate confidence based on data quality and correlation strength

OUTPUT FORMAT (JSON):
{
  "analysis": {
    "data_quality": {
      "track_count": 150,
      "genre_count": 12,
      "data_span_days": 90,
      "quality_score": 0.85
    },
    "audio_profile": {
      "avg_energy": 0.65,
      "avg_valence": 0.55,
      "avg_tempo": 118,
      "avg_acousticness": 0.25,
      "avg_danceability": 0.70
    },
    "genre_profile": {
      "dominant_category": "energetic_rhythmic",
      "diversity_score": 0.72,
      "top_genres": ["hip-hop", "electronic", "pop"]
    }
  },
  "personality_evidence": {
    "openness": {
      "score": 68,
      "confidence": 0.75,
      "evidence": [
        {
          "feature": "genre_diversity",
          "value": 0.72,
          "correlation": 0.40,
          "citation": "Rentfrow & Gosling (2003)",
          "description": "High genre diversity (12 genres) indicates intellectual curiosity"
        }
      ]
    },
    "conscientiousness": { ... },
    "extraversion": { ... },
    "agreeableness": { ... },
    "neuroticism": { ... }
  },
  "summary": "Based on your Spotify listening patterns...",
  "research_context": "Analysis grounded in music psychology research..."
}

CORRELATION GUIDELINES:
- r â‰¥ 0.35: Strong evidence, high confidence contribution
- r = 0.25-0.34: Moderate evidence, medium confidence
- r < 0.25: Weak evidence, low confidence contribution

IMPORTANT:
- Always cite specific research papers
- Be transparent about correlation strengths
- Acknowledge limitations when data is sparse
- Focus on statistically significant correlations only`;
  }

  initializeTools() {
    this.addTool({
      name: 'get_spotify_data',
      description: `Retrieve user's Spotify listening data including audio features, genres, and patterns.

Returns:
- Audio feature averages (energy, valence, tempo, etc.)
- Genre distribution and diversity
- Listening patterns and consistency
- Discovery rate (new artists)`,
      input_schema: {
        type: 'object',
        properties: {
          user_id: { type: 'string', description: 'User ID to fetch data for' }
        },
        required: ['user_id']
      }
    });

    this.addTool({
      name: 'get_research_context',
      description: `Retrieve relevant music psychology research for a specific personality dimension.

Returns research papers, correlations, and citations relevant to the inference.`,
      input_schema: {
        type: 'object',
        properties: {
          dimension: { type: 'string', enum: ['openness', 'conscientiousness', 'extraversion', 'agreeableness', 'neuroticism'] },
          feature: { type: 'string', description: 'Music feature being analyzed (e.g., genre_diversity, energy)' }
        },
        required: ['dimension', 'feature']
      }
    });

    this.addTool({
      name: 'calculate_personality_scores',
      description: `Calculate Big Five personality scores from Spotify features using validated correlations.

Applies research-backed correlations to compute scores with confidence intervals.`,
      input_schema: {
        type: 'object',
        properties: {
          audio_features: {
            type: 'object',
            description: 'Average audio features (energy, valence, tempo, etc.)'
          },
          genre_profile: {
            type: 'object',
            description: 'Genre distribution and categories'
          },
          behavioral_patterns: {
            type: 'object',
            description: 'Listening patterns (consistency, discovery rate)'
          }
        },
        required: ['audio_features']
      }
    });
  }

  /**
   * Execute music psychology analysis
   */
  async execute(prompt, options = {}) {
    const userId = options.userId;

    if (!userId) {
      throw new Error('MusicPsychologyAgent requires userId in options');
    }

    this._currentUserId = userId;

    try {
      const response = await super.execute(prompt, options);

      if (response.toolUses && response.toolUses.length > 0) {
        const toolResults = await this.executeTools(response.toolUses, userId);
        const followUpResponse = await this.continueWithToolResults(
          prompt,
          response,
          toolResults,
          options
        );
        return followUpResponse;
      }

      return response;

    } finally {
      this._currentUserId = null;
    }
  }

  /**
   * Execute tool calls
   */
  async executeTools(toolUses, userId) {
    const results = [];

    for (const toolUse of toolUses) {
      console.log(`ðŸŽµ [MusicPsychologyAgent] Executing tool: ${toolUse.name}`);

      try {
        let result;

        switch (toolUse.name) {
          case 'get_spotify_data':
            result = await this.getSpotifyData(userId);
            break;

          case 'get_research_context':
            result = await this.getResearchContext(toolUse.input);
            break;

          case 'calculate_personality_scores':
            result = await this.calculatePersonalityScores(toolUse.input);
            break;

          default:
            result = { error: `Unknown tool: ${toolUse.name}` };
        }

        results.push({
          tool_use_id: toolUse.id,
          type: 'tool_result',
          content: JSON.stringify(result)
        });

      } catch (error) {
        console.error(`âŒ Tool ${toolUse.name} failed:`, error);
        results.push({
          tool_use_id: toolUse.id,
          type: 'tool_result',
          is_error: true,
          content: error.message
        });
      }
    }

    return results;
  }

  /**
   * Continue conversation with tool results
   */
  async continueWithToolResults(originalPrompt, firstResponse, toolResults, options) {
    const messages = [
      { role: 'user', content: originalPrompt },
      { role: 'assistant', content: firstResponse.raw.content },
      { role: 'user', content: toolResults }
    ];

    const response = await this.client.messages.create({
      model: this.model,
      max_tokens: this.maxTokens,
      temperature: this.temperature,
      system: this.systemPrompt,
      messages,
      tools: this.tools
    });

    return this.processResponse(response);
  }

  /**
   * Tool: Get Spotify data for user
   */
  async getSpotifyData(userId) {
    console.log(`ðŸŽµ [MusicPsychologyAgent] Fetching Spotify data for ${userId}`);

    const supabase = getSupabaseClient();

    // Get extracted Spotify features
    const { data: features, error: featuresError } = await supabase
      .from('extracted_platform_features')
      .select('*')
      .eq('user_id', userId)
      .eq('platform', 'spotify');

    // Get raw Spotify data
    const { data: rawData, error: rawError } = await supabase
      .from('platform_raw_data')
      .select('data')
      .eq('user_id', userId)
      .eq('platform', 'spotify')
      .order('extracted_at', { ascending: false })
      .limit(1)
      .single();

    if (featuresError && rawError) {
      return {
        hasData: false,
        message: 'No Spotify data found for user',
        recommendation: 'Connect Spotify to enable music-based personality analysis'
      };
    }

    // Extract audio features
    const audioFeatures = this.extractAudioFeatures(features || [], rawData?.data);
    const genreProfile = this.extractGenreProfile(features || [], rawData?.data);
    const behavioralPatterns = this.extractBehavioralPatterns(features || [], rawData?.data);

    return {
      hasData: true,
      audioFeatures,
      genreProfile,
      behavioralPatterns,
      dataQuality: this.assessDataQuality(features, rawData?.data)
    };
  }

  /**
   * Extract audio features from Spotify data
   */
  extractAudioFeatures(features, rawData) {
    // Try to get from extracted features first
    const audioFeature = features.find(f => f.feature_type === 'audio_features_avg');
    if (audioFeature?.metadata?.averages) {
      return audioFeature.metadata.averages;
    }

    // Fall back to calculating from raw data
    if (rawData?.recentTracks?.items) {
      const tracks = rawData.recentTracks.items;
      // Note: In a real implementation, would need to fetch audio features from Spotify API
      return {
        energy: 0.5,
        valence: 0.5,
        tempo: 120,
        acousticness: 0.3,
        danceability: 0.6,
        instrumentalness: 0.1,
        liveness: 0.2,
        speechiness: 0.1
      };
    }

    return null;
  }

  /**
   * Extract genre profile from Spotify data
   */
  extractGenreProfile(features, rawData) {
    const genreFeature = features.find(f => f.feature_type === 'genre_diversity');
    const genres = {};
    let genreCount = 0;

    // Extract from raw data
    if (rawData?.topArtists?.items) {
      for (const artist of rawData.topArtists.items) {
        if (artist.genres) {
          for (const genre of artist.genres) {
            genres[genre] = (genres[genre] || 0) + 1;
            genreCount++;
          }
        }
      }
    }

    // Categorize genres
    const categoryScores = {
      reflective_complex: 0,
      intense_rebellious: 0,
      upbeat_conventional: 0,
      energetic_rhythmic: 0
    };

    for (const [genre, count] of Object.entries(genres)) {
      const lowerGenre = genre.toLowerCase();
      for (const [category, keywords] of Object.entries(this.genreCategories)) {
        if (keywords.some(kw => lowerGenre.includes(kw))) {
          categoryScores[category] += count;
        }
      }
    }

    const total = Object.values(categoryScores).reduce((a, b) => a + b, 0);
    const dominantCategory = Object.entries(categoryScores)
      .sort((a, b) => b[1] - a[1])[0]?.[0];

    return {
      genreCount: Object.keys(genres).length,
      topGenres: Object.entries(genres)
        .sort((a, b) => b[1] - a[1])
        .slice(0, 5)
        .map(([g]) => g),
      categoryScores: total > 0 ? Object.fromEntries(
        Object.entries(categoryScores).map(([k, v]) => [k, v / total])
      ) : categoryScores,
      dominantCategory,
      diversityScore: genreFeature?.normalized_value || this.calculateDiversity(Object.keys(genres).length)
    };
  }

  /**
   * Extract behavioral patterns from Spotify data
   */
  extractBehavioralPatterns(features, rawData) {
    const discoveryFeature = features.find(f => f.feature_type === 'discovery_rate');
    const consistencyFeature = features.find(f => f.feature_type === 'listening_consistency');

    return {
      discoveryRate: discoveryFeature?.normalized_value || 0.3,
      listeningConsistency: consistencyFeature?.normalized_value || 0.5,
      playlistCount: rawData?.playlists?.total || 0,
      savedTracksCount: rawData?.savedTracks?.total || 0
    };
  }

  /**
   * Assess data quality
   */
  assessDataQuality(features, rawData) {
    let score = 0;
    let trackCount = 0;
    let dataSpanDays = 0;

    if (rawData?.recentTracks?.items) {
      trackCount = rawData.recentTracks.items.length;
      score += Math.min(trackCount / 50, 0.3); // Max 0.3 for track count
    }

    if (features && features.length > 0) {
      score += Math.min(features.length / 10, 0.3); // Max 0.3 for feature count

      const dates = features
        .map(f => new Date(f.created_at))
        .filter(d => !isNaN(d));
      if (dates.length > 0) {
        const oldest = Math.min(...dates);
        const newest = Math.max(...dates);
        dataSpanDays = Math.floor((newest - oldest) / (1000 * 60 * 60 * 24));
        score += Math.min(dataSpanDays / 30, 0.2); // Max 0.2 for data span
      }
    }

    if (rawData?.topArtists?.items?.length) {
      score += 0.2; // Bonus for having top artists
    }

    return {
      score: Math.min(score, 1),
      trackCount,
      dataSpanDays,
      featureCount: features?.length || 0
    };
  }

  /**
   * Calculate diversity score
   */
  calculateDiversity(genreCount) {
    // Simple normalization: 1 genre = 0.1, 10+ genres = 1.0
    return Math.min(genreCount / 10, 1);
  }

  /**
   * Tool: Get research context from RAG
   */
  async getResearchContext(params) {
    const { dimension, feature } = params;

    try {
      const context = await researchRAGService.getResearchContext(dimension, feature);
      return context;
    } catch (error) {
      console.error(`[MusicPsychologyAgent] RAG error:`, error);
      return {
        hasResearch: false,
        fallbackCorrelation: this.correlations[feature]?.[dimension] || null,
        message: 'RAG unavailable, using built-in correlations'
      };
    }
  }

  /**
   * Tool: Calculate personality scores
   */
  async calculatePersonalityScores(params) {
    const { audio_features, genre_profile, behavioral_patterns } = params;

    const scores = {
      openness: { score: 50, confidence: 0, evidence: [] },
      conscientiousness: { score: 50, confidence: 0, evidence: [] },
      extraversion: { score: 50, confidence: 0, evidence: [] },
      agreeableness: { score: 50, confidence: 0, evidence: [] },
      neuroticism: { score: 50, confidence: 0, evidence: [] }
    };

    // Apply audio feature correlations
    if (audio_features) {
      this.applyAudioCorrelations(scores, audio_features);
    }

    // Apply genre correlations
    if (genre_profile) {
      this.applyGenreCorrelations(scores, genre_profile);
    }

    // Apply behavioral correlations
    if (behavioral_patterns) {
      this.applyBehavioralCorrelations(scores, behavioral_patterns);
    }

    // Normalize scores to 0-100 range
    for (const dimension of Object.keys(scores)) {
      scores[dimension].score = Math.max(0, Math.min(100, Math.round(scores[dimension].score)));
      scores[dimension].confidence = Math.min(0.95, scores[dimension].confidence);
    }

    return scores;
  }

  /**
   * Apply audio feature correlations
   */
  applyAudioCorrelations(scores, audioFeatures) {
    const features = ['energy', 'valence', 'tempo', 'acousticness', 'danceability'];

    for (const feature of features) {
      const value = audioFeatures[feature];
      if (value === undefined) continue;

      const correlations = this.correlations[feature];
      if (!correlations) continue;

      for (const [dimension, corr] of Object.entries(correlations)) {
        // Normalize tempo (60-180 -> 0-1)
        const normalizedValue = feature === 'tempo'
          ? (value - 60) / 120
          : value;

        // Calculate contribution based on correlation
        const contribution = corr.direction === 'positive'
          ? (normalizedValue - 0.5) * corr.r * 30 // Scale to ~Â±15 points max
          : -(normalizedValue - 0.5) * Math.abs(corr.r) * 30;

        scores[dimension].score += contribution;
        scores[dimension].confidence += Math.abs(corr.r) * 0.1; // Build confidence

        // Add evidence
        scores[dimension].evidence.push({
          feature,
          value: normalizedValue,
          rawValue: value,
          correlation: corr.r,
          direction: corr.direction,
          citation: 'Anderson et al. (2021)',
          description: this.generateEvidenceDescription(feature, value, dimension, corr)
        });
      }
    }
  }

  /**
   * Apply genre-based correlations
   */
  applyGenreCorrelations(scores, genreProfile) {
    // Genre diversity -> Openness
    if (genreProfile.diversityScore !== undefined) {
      const corr = this.correlations.genre_diversity;
      if (corr?.openness) {
        const contribution = (genreProfile.diversityScore - 0.5) * corr.openness.r * 40;
        scores.openness.score += contribution;
        scores.openness.confidence += corr.openness.r * 0.15;

        scores.openness.evidence.push({
          feature: 'genre_diversity',
          value: genreProfile.diversityScore,
          rawValue: { genre_count: genreProfile.genreCount },
          correlation: corr.openness.r,
          direction: 'positive',
          citation: 'Rentfrow & Gosling (2003)',
          description: `Explored ${genreProfile.genreCount} music genres, indicating ${genreProfile.diversityScore > 0.6 ? 'high' : 'moderate'} openness to new experiences`
        });
      }
    }

    // Genre categories
    if (genreProfile.categoryScores) {
      const categoryCorrelations = {
        reflective_complex: { openness: { r: 0.40, direction: 'positive' } },
        intense_rebellious: { openness: { r: 0.35, direction: 'positive' } },
        upbeat_conventional: {
          conscientiousness: { r: 0.20, direction: 'positive' },
          agreeableness: { r: 0.20, direction: 'positive' },
          openness: { r: -0.25, direction: 'negative' }
        },
        energetic_rhythmic: { extraversion: { r: 0.30, direction: 'positive' } }
      };

      for (const [category, proportion] of Object.entries(genreProfile.categoryScores)) {
        const corrs = categoryCorrelations[category];
        if (!corrs || proportion < 0.1) continue;

        for (const [dimension, corr] of Object.entries(corrs)) {
          const contribution = corr.direction === 'positive'
            ? proportion * corr.r * 25
            : -proportion * Math.abs(corr.r) * 25;

          scores[dimension].score += contribution;
          scores[dimension].confidence += proportion * Math.abs(corr.r) * 0.1;
        }
      }

      // Add evidence for dominant category
      if (genreProfile.dominantCategory) {
        const desc = {
          reflective_complex: 'Preference for reflective, complex music (jazz, classical, blues)',
          intense_rebellious: 'Preference for intense, rebellious music (rock, metal, alternative)',
          upbeat_conventional: 'Preference for upbeat, conventional music (pop, country)',
          energetic_rhythmic: 'Preference for energetic, rhythmic music (hip-hop, electronic, dance)'
        };

        const dominantCorrs = categoryCorrelations[genreProfile.dominantCategory];
        if (dominantCorrs) {
          for (const [dimension, corr] of Object.entries(dominantCorrs)) {
            scores[dimension].evidence.push({
              feature: `genre_${genreProfile.dominantCategory}`,
              value: genreProfile.categoryScores[genreProfile.dominantCategory],
              rawValue: { top_genres: genreProfile.topGenres },
              correlation: corr.r,
              direction: corr.direction,
              citation: 'Rentfrow & Gosling (2003)',
              description: desc[genreProfile.dominantCategory]
            });
          }
        }
      }
    }
  }

  /**
   * Apply behavioral pattern correlations
   */
  applyBehavioralCorrelations(scores, patterns) {
    // Discovery rate -> Openness
    if (patterns.discoveryRate !== undefined) {
      const corr = this.correlations.discovery_rate;
      if (corr?.openness) {
        const contribution = (patterns.discoveryRate - 0.3) * corr.openness.r * 30;
        scores.openness.score += contribution;
        scores.openness.confidence += corr.openness.r * 0.1;

        scores.openness.evidence.push({
          feature: 'discovery_rate',
          value: patterns.discoveryRate,
          rawValue: { new_artists_percent: Math.round(patterns.discoveryRate * 100) },
          correlation: corr.openness.r,
          direction: 'positive',
          citation: 'Anderson et al. (2021)',
          description: `${Math.round(patterns.discoveryRate * 100)}% of listening involves new artists, suggesting openness to new experiences`
        });
      }
    }

    // Listening consistency -> Conscientiousness
    if (patterns.listeningConsistency !== undefined) {
      const corr = this.correlations.listening_consistency;
      if (corr?.conscientiousness) {
        const contribution = (patterns.listeningConsistency - 0.5) * corr.conscientiousness.r * 25;
        scores.conscientiousness.score += contribution;
        scores.conscientiousness.confidence += corr.conscientiousness.r * 0.1;

        scores.conscientiousness.evidence.push({
          feature: 'listening_consistency',
          value: patterns.listeningConsistency,
          rawValue: { consistency_score: Math.round(patterns.listeningConsistency * 100) },
          correlation: corr.conscientiousness.r,
          direction: 'positive',
          citation: 'Stachl et al. (2020)',
          description: patterns.listeningConsistency > 0.6
            ? 'Consistent daily listening patterns suggest organized, routine-oriented behavior'
            : 'Variable listening patterns suggest flexible, adaptable behavior'
        });
      }
    }
  }

  /**
   * Generate evidence description
   */
  generateEvidenceDescription(feature, value, dimension, corr) {
    const templates = {
      energy: {
        high: `High-energy music preference (${Math.round(value * 100)}%) correlates with ${dimension}`,
        low: `Low-energy music preference (${Math.round(value * 100)}%) correlates with ${dimension}`
      },
      valence: {
        high: `Preference for positive/happy music (valence: ${Math.round(value * 100)}%)`,
        low: `Preference for melancholic music (valence: ${Math.round(value * 100)}%)`
      },
      tempo: {
        high: `Fast tempo preference (${Math.round(value)} BPM) suggests ${dimension === 'extraversion' ? 'extraverted' : dimension} tendencies`,
        low: `Slower tempo preference (${Math.round(value)} BPM)`
      },
      acousticness: {
        high: `Preference for acoustic music (${Math.round(value * 100)}%) correlates with ${dimension}`,
        low: `Preference for electronic/produced music (${Math.round((1 - value) * 100)}%)`
      },
      danceability: {
        high: `High danceability preference (${Math.round(value * 100)}%) suggests ${dimension} tendencies`,
        low: `Low danceability preference (${Math.round(value * 100)}%)`
      }
    };

    const normalized = feature === 'tempo' ? (value - 60) / 120 : value;
    const level = normalized > 0.5 ? 'high' : 'low';

    return templates[feature]?.[level] || `${feature}: ${Math.round(value * 100)}%`;
  }

  /**
   * Main analysis method - analyze user's Spotify data for personality
   */
  async analyzeForPersonality(userId) {
    console.log(`ðŸŽµ [MusicPsychologyAgent] Starting analysis for user ${userId}`);

    const prompt = `Analyze the Spotify data for this user and provide Big Five personality inferences.

Use your tools to:
1. First, get the user's Spotify data
2. Calculate personality scores based on the validated correlations
3. Return a comprehensive analysis with evidence and citations

Be thorough and cite specific research for each inference.`;

    const result = await this.execute(prompt, { userId });

    // Parse the response
    try {
      const analysis = this.parseJSON(result.text);
      return {
        success: true,
        analysis,
        agentMetrics: this.getMetrics()
      };
    } catch (error) {
      console.error(`[MusicPsychologyAgent] Failed to parse response:`, error);
      return {
        success: false,
        rawResponse: result.text,
        error: 'Failed to parse agent response'
      };
    }
  }
}

export default MusicPsychologyAgent;
